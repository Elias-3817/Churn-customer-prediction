
# ğŸ“Š Customer Churn Prediction

Predict and prevent customer churn to drive retention strategies and protect revenue.

---

## ğŸš€ Project Overview

Churn is a silent revenue killer. In this endâ€‘toâ€‘end project, we:

- **Cleaned & Explored** a realâ€‘world telecom dataset (EDA, hypothesis testing, null handling, )
- **Feature engineered** (Label encoding,Standardised numerical features)
- **Tuned & Compared** three classifiers: Logistic Regression, Random Forest, XGBoost
- **Optimized Threshold** for Recall â‰¥ 75% using costâ€‘sensitive analysis (FN = $70, FP = $10, TP benefit = $70)
- **Validated Performance** with 5â€‘fold CV and holdâ€‘out test set
- **Simulated Business Impact**: projected \$58Kâ€“\$101K monthly in net savings

Our final model enables surgical retention campaigns by flagging the highestâ€‘risk customers.

---

## ğŸ“‚ Repository Structure

```
â”œâ”€â”€ data/                                # Cleaned train/val/test CSVs
â”œâ”€â”€ models/                              # Saved Random Forest model + threshold
â”œâ”€â”€ notebooks/                           # Step-by-step analysis notebooks
â”‚   â”œâ”€â”€ 01_problem_and_goals.ipynb
â”‚   â”œâ”€â”€ 02_data_cleaning_and_eda.ipynb
â”‚   â”œâ”€â”€ 03_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 04_model_comparison_and_tuning.ipynb
â”‚   â””â”€â”€ 05_evaluation_and_cost_analysis.ipynb
â”œâ”€â”€ deployment_script.py                 # Load model & predict function (In progress)
â”œâ”€â”€ Dashboard/                          # Final model dashboard 
â”œâ”€â”€ requirements.txt                     # Python dependencies
|â”€â”€ README.md                            # Project overview (this file)


---

## ğŸ› ï¸ Tech Stack

- **Language & Libraries**: Python, Pandas, NumPy, scikit-learn, XGBoost, Matplotlib, Seaborn
- **Feature Engineering**: Label Encoding, Oneâ€‘Hot Encoding, Scaling (StandardScaler)
- **Modeling**: Logistic Regression, Random Forest, XGBoost
- **Evaluation**: Precision, Recall, F1â€‘Score, Confusion Matrix, Crossâ€‘Validation
- **Business Analysis**: Costâ€‘Critical Threshold Tuning, ROI Simulation
- **Environment & Tools**: Jupyter Notebooks, Power BI (dashboard), Git & GitHub
---

## ğŸ“ˆ Final Model: Random Forest (Businessâ€‘Optimized)

| Metric                       | Value   |
|------------------------------|--------:|
| **Model**                    | Random Forest (n_estimators=100, max_depth=5)  |
| **Threshold**                | 0.503   |
| **Precision (Churn)**        | 0.564   |
| **Recall (Churn)**           | 0.751   |
| **F1â€‘Score (Churn)**         | 0.640   |
| **Accuracy**                 | 0.78    |
| **Projected Monthly Savings**| \$58,104 (conservative) / \$101,110 (full scale)|

> We selected this configuration to maximize net savings while maintaining strong churn detection.

---

## ğŸ’¡ Key Business Insights

- **Highâ€‘risk segments**: Short tenure, electronic check payers, fiber internet users
- **Action levers**: Incentivize autoâ€‘pay, premium support for fiber users, targeted offers for new customers
- **Impact**: Dataâ€‘driven interventions can **double** the savings compared to blanket churn reduction targets

---

## ğŸŒ Deployment Ready (still in progress)

- **Model** and **threshold** saved in `models/`:
  - `rf_churn_model.pkl`
  - `rf_threshold.pkl`
- **Deployment Script**: `deployment_script.py` provides a `predict_churn()` function for new customer data 
---

## ğŸ“Š Next Steps

- **Productionize** with Streamlit or FastAPI endpoint
- **Connect** to live customer database for automated scoring
- **Monitor & Retrain** quarterly to adapt to behavior shifts
- **Interpretability**: integrate SHAP values for stakeholder transparency

---

## ğŸ‘¤ Author

**Elias Gichuru**  
 Data Analyst | Machine Learning Engineer  
[GitHub Profile](https://github.com/Elias-3817)  
[LinkedIn Profile](https://www.linkedin.com/in/elias-gichuru-56a2a3250/)  
